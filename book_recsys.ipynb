{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Book Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "- The data comes from [Goodbooks dataset](https://github.com/zygmuntz/goodbooks-10k).\n",
    "- The dataset contains 10,000 books and 5,976,479 ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 files that will be used:\n",
    "\n",
    "\n",
    "**Book rating data**: `ratings.csv`\n",
    "\n",
    "<center>\n",
    "\n",
    "|Feature|Description|Data Type|\n",
    "|:--|:--|:--:|\n",
    "|`user_id`|User ID|`int`|\n",
    "|`book_id`|BookID|`int`|\n",
    "|`rating`|The rating of the book given by the user. Rating starts from `0` to `5`|`int`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|**Books data** : `books.csv`\n",
    "\n",
    "<center>\n",
    "\n",
    "|Feature|Description|Data Type|\n",
    "|:--|:--|:--:|\n",
    "|`book_id`|Book ID|`int`|\n",
    "|`goodreads_book_id`|The goodreads book ID|`int`|\n",
    "|`best_book_id`|Rating of the book given by the user. Rating starts from `0` to `5`|`int`|\n",
    "|`work_id`|Work ID|`int`|\n",
    "|`books_count`|Books count|`int`|\n",
    "|`isbn`|International standard book number|`object`|\n",
    "|`isbn13`|Book identification number (new version of ISBN)|`float`|\n",
    "|`authors`|The authors of the book|`object`|\n",
    "|`original_publication_year`|The year of publication|`float`|\n",
    "|`original_title`|Original title|`object`|\n",
    "|`title`|Book title|`object`|\n",
    "|`language_code`|Code of language|`object`|\n",
    "|`average_rating`|Average rating|`float`|\n",
    "|`ratings_count`|Rating count|`int`|\n",
    "|`work_ratings_count`|Work ratings count|`int`|\n",
    "|`work_text_reviews_count`|Work text reviews count|`int`|\n",
    "|`ratings_1`|Rating 1|`int`|\n",
    "|`ratings_2`|Rating 2|`int`|\n",
    "|`ratings_3`|Rating 3|`int`|\n",
    "|`ratings_4`|Rating 4|`int`|\n",
    "|`ratings_5`|Rating 5|`int`|\n",
    "|`image_url`|Image link|`object`|\n",
    "|`small_image_url`|Small image links|`object`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Import Data dan Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:25.951332Z",
     "iopub.status.busy": "2023-08-31T06:42:25.950551Z",
     "iopub.status.idle": "2023-08-31T06:42:27.101252Z",
     "shell.execute_reply": "2023-08-31T06:42:27.100629Z",
     "shell.execute_reply.started": "2023-08-31T06:42:25.951304Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:27.102735Z",
     "iopub.status.busy": "2023-08-31T06:42:27.102373Z",
     "iopub.status.idle": "2023-08-31T06:42:27.105749Z",
     "shell.execute_reply": "2023-08-31T06:42:27.105250Z",
     "shell.execute_reply.started": "2023-08-31T06:42:27.102713Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load data from path\n",
    "rating_path = 'data/ratings.csv'\n",
    "book_path = 'data/books.csv'\n",
    "book_tags_path = 'data/book_tags.csv'\n",
    "tags_path = 'data/tags.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:27.106825Z",
     "iopub.status.busy": "2023-08-31T06:42:27.106562Z",
     "iopub.status.idle": "2023-08-31T06:42:27.113581Z",
     "shell.execute_reply": "2023-08-31T06:42:27.113079Z",
     "shell.execute_reply.started": "2023-08-31T06:42:27.106806Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(book_path, rating_path):\n",
    "    \"\"\"\n",
    "    \n",
    "    Function to load book and rating data\n",
    "    - subsetting only the used columns\n",
    "    - fill in missing values\n",
    "    - drop duplicate rows\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    # reads the CSV file data and saves it as a DataFrame\n",
    "    rating_data = pd.read_csv(rating_path, delimiter=',')\n",
    "    book_data = pd.read_csv(book_path, delimiter=',')\n",
    "    \n",
    "    # copy dataframe book_data, and delete some feature.\n",
    "    book_copy = book_data.copy()\n",
    "    book_copy = book_copy.drop(columns=['best_book_id','work_id','books_count','isbn',\n",
    "           'isbn13','title','language_code','average_rating',\n",
    "           'ratings_count', 'work_ratings_count', 'work_text_reviews_count',\n",
    "           'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5',\n",
    "           'small_image_url'], axis=1)\n",
    "    book_copy.head(3)\n",
    "    \n",
    "    # fill null values in book_data\n",
    "    print(\"Missing values before fillna: \", book_copy.isnull().sum())\n",
    "    book_copy['original_publication_year'] = book_copy['original_publication_year'].fillna(0)\n",
    "    book_copy['original_title'] = book_copy['original_title'].fillna(book_data['title'])\n",
    "    print(\"Missing values after fillna: \", book_copy.isnull().sum())\n",
    "    \n",
    "    # changes the data type original_publication_year column to int data type\n",
    "    book_copy.loc[:, 'original_publication_year'] = book_copy['original_publication_year'].astype(int)\n",
    "    book_copy.dtypes\n",
    "    \n",
    "    # drop duplicated rows\n",
    "    print(\"Books shape before drop dup: \", book_copy.shape)\n",
    "    print(\"Ratings shape before drop dup: \", rating_data.shape)\n",
    "    book_copy.drop_duplicates(subset = ['book_id', 'goodreads_book_id'], inplace = True)\n",
    "    rating_data.drop_duplicates(subset=['user_id','book_id'], inplace = True)\n",
    "    print(\"Books shape after drop dup: \", book_copy.shape)\n",
    "    print(\"Ratings shape after drop dup: \", rating_data.shape)\n",
    "    \n",
    "    return book_copy, rating_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:27.114888Z",
     "iopub.status.busy": "2023-08-31T06:42:27.114643Z",
     "iopub.status.idle": "2023-08-31T06:42:29.072970Z",
     "shell.execute_reply": "2023-08-31T06:42:29.072136Z",
     "shell.execute_reply.started": "2023-08-31T06:42:27.114869Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before fillna:  book_id                        0\n",
      "goodreads_book_id              0\n",
      "authors                        0\n",
      "original_publication_year     21\n",
      "original_title               585\n",
      "image_url                      0\n",
      "dtype: int64\n",
      "Missing values after fillna:  book_id                      0\n",
      "goodreads_book_id            0\n",
      "authors                      0\n",
      "original_publication_year    0\n",
      "original_title               0\n",
      "image_url                    0\n",
      "dtype: int64\n",
      "Books shape before drop dup:  (10000, 6)\n",
      "Ratings shape before drop dup:  (5976479, 3)\n",
      "Books shape after drop dup:  (10000, 6)\n",
      "Ratings shape after drop dup:  (5976479, 3)\n"
     ]
    }
   ],
   "source": [
    "book_copy, rating_data = load_data(book_path, rating_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**rating_data** has the correct type and feature. There is no null data and duplicated in rating_data.\n",
    "\n",
    "**book_copy** has the correct feature. The data type in 'original_publication_year' has been corrected. There is no duplicated in book_copy and null data has been removed.**book_copy** has the correct feature. The data type in 'original_publication_year' has been corrected. There is no duplicated in book_copy and null data has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:29.074409Z",
     "iopub.status.busy": "2023-08-31T06:42:29.073895Z",
     "iopub.status.idle": "2023-08-31T06:42:29.082198Z",
     "shell.execute_reply": "2023-08-31T06:42:29.081446Z",
     "shell.execute_reply.started": "2023-08-31T06:42:29.074387Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_id                       int64\n",
       "goodreads_book_id             int64\n",
       "authors                      object\n",
       "original_publication_year     int64\n",
       "original_title               object\n",
       "image_url                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the datatype of book_data\n",
    "book_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:29.084393Z",
     "iopub.status.busy": "2023-08-31T06:42:29.084080Z",
     "iopub.status.idle": "2023-08-31T06:42:29.096597Z",
     "shell.execute_reply": "2023-08-31T06:42:29.095795Z",
     "shell.execute_reply.started": "2023-08-31T06:42:29.084349Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  goodreads_book_id                      authors  \\\n",
       "0        1            2767052              Suzanne Collins   \n",
       "1        2                  3  J.K. Rowling, Mary GrandPré   \n",
       "2        3              41865              Stephenie Meyer   \n",
       "\n",
       "   original_publication_year                            original_title  \\\n",
       "0                       2008                          The Hunger Games   \n",
       "1                       1997  Harry Potter and the Philosopher's Stone   \n",
       "2                       2005                                  Twilight   \n",
       "\n",
       "                                           image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603m...  \n",
       "1  https://images.gr-assets.com/books/1474154022m...  \n",
       "2  https://images.gr-assets.com/books/1361039443m...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show book_data\n",
    "book_copy.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Tags Data to obtain book genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:29.097755Z",
     "iopub.status.busy": "2023-08-31T06:42:29.097490Z",
     "iopub.status.idle": "2023-08-31T06:42:29.344780Z",
     "shell.execute_reply": "2023-08-31T06:42:29.344144Z",
     "shell.execute_reply.started": "2023-08-31T06:42:29.097736Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Memisahkan 40 Genre\n",
    "\n",
    "book_tags = pd.read_csv(book_tags_path, delimiter=',')\n",
    "tags = pd.read_csv(tags_path, delimiter=',')\n",
    "\n",
    "genres = [\"Art\", \"Biography\", \"Business\", \"Chick Lit\", \"Children\", \"Christian\", \"Classics\",\n",
    "          \"Comics\", \"Contemporary\", \"Cookbooks\", \"Crime\", \"Ebooks\", \"Fantasy\", \"Fiction\",\n",
    "          \"Gay and Lesbian\", \"Graphic Novels\", \"Historical Fiction\", \"History\", \"Horror\",\n",
    "          \"Humor and Comedy\", \"Manga\", \"Memoir\", \"Music\", \"Mystery\", \"Nonfiction\", \"Paranormal\",\n",
    "          \"Philosophy\", \"Poetry\", \"Psychology\", \"Religion\", \"Romance\", \"Science\", \"Science Fiction\", \n",
    "          \"Self Help\", \"Suspense\", \"Spirituality\", \"Sports\", \"Thriller\", \"Travel\", \"Young Adult\"]\n",
    "\n",
    "genres = list(map(str.lower, genres))\n",
    "\n",
    "def create_genre_list(tag):\n",
    "    \"\"\"\n",
    "    Function for building list of extracted genres\n",
    "    \"\"\"\n",
    "    genre_list = []\n",
    "    string_tag = str(tag)\n",
    "    \n",
    "    for genre in genres:\n",
    "        \n",
    "        if ('nonfiction' in string_tag):\n",
    "            genre_list.append('nonfiction')\n",
    "        elif (genre in string_tag) & ('non' not in string_tag):\n",
    "            genre_list.append(genre)\n",
    "        elif ('sci-fi' in string_tag) | ('scifi' in string_tag):\n",
    "            genre_list.append('science fiction')\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return genre_list\n",
    "\n",
    "\n",
    "def unique_array(list_):\n",
    "    unique_list = list(set(list_))\n",
    "    return unique_list\n",
    "\n",
    "def extract_genres(book_tags, tags, genres):\n",
    "    \"\"\"\n",
    "    Function to extract genres from tag names\n",
    "    \"\"\"\n",
    "    tags['tag_name_lower'] = tags['tag_name'].str.lower()\n",
    "    available_genres = tags.loc[tags.tag_name_lower.str.lower().isin(genres)]\n",
    "    available_genres.head()\n",
    "    \n",
    "    tags['genre_list'] = [[]] * tags.shape[0]   \n",
    "\n",
    "    # Add tags\n",
    "    tags['genre_list'] = tags.apply(lambda row: create_genre_list(row['tag_name_lower']), axis = 1)\n",
    "    tags_filtered = tags[tags.genre_list.str.len() != 0]\n",
    "    \n",
    "    # join with books\n",
    "    booktags_to_genre = pd.merge(book_tags, tags_filtered, how = \"left\", on = \"tag_id\")\n",
    "    booktags_to_genre.dropna(subset = [\"genre_list\"], inplace = True)\n",
    "    booktags_to_genre.drop(['tag_id', 'tag_name', 'tag_name_lower', 'count'], axis=1, inplace = True)\n",
    "    gr_book_genres = booktags_to_genre.groupby('goodreads_book_id').agg({'genre_list': 'sum'}).reset_index(drop = False)\n",
    "\n",
    "    gr_book_genres['genres'] = gr_book_genres.apply(lambda row: unique_array(row['genre_list']), axis = 1)\n",
    "    gr_book_genres.drop(['genre_list'], axis = 1, inplace = True)\n",
    "    \n",
    "    # Join with books\n",
    "    books_with_genres = pd.merge(book_copy, gr_book_genres, how = \"left\", on = \"goodreads_book_id\")\n",
    "    books_with_genres = books_with_genres[[\"book_id\", \"genres\"]]\n",
    "    \n",
    "    return books_with_genres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:29.345915Z",
     "iopub.status.busy": "2023-08-31T06:42:29.345635Z",
     "iopub.status.idle": "2023-08-31T06:42:30.394080Z",
     "shell.execute_reply": "2023-08-31T06:42:30.393243Z",
     "shell.execute_reply.started": "2023-08-31T06:42:29.345890Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[thriller, science, fiction, fantasy, suspense...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[mystery, science, fiction, fantasy, children,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[science, fiction, fantasy, horror, contempora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[mystery, fiction, crime, history, contemporar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[fiction, ebooks, romance, classics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>[mystery, fiction, fantasy, art, contemporary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>[science, nonfiction, history, art, memoir, bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>[fiction, history, contemporary, ebooks, class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>[science, psychology, nonfiction, children, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>[fiction, nonfiction, history, biography, ebooks]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id                                             genres\n",
       "0           1  [thriller, science, fiction, fantasy, suspense...\n",
       "1           2  [mystery, science, fiction, fantasy, children,...\n",
       "2           3  [science, fiction, fantasy, horror, contempora...\n",
       "3           4  [mystery, fiction, crime, history, contemporar...\n",
       "4           5               [fiction, ebooks, romance, classics]\n",
       "...       ...                                                ...\n",
       "9995     9996  [mystery, fiction, fantasy, art, contemporary,...\n",
       "9996     9997  [science, nonfiction, history, art, memoir, bi...\n",
       "9997     9998  [fiction, history, contemporary, ebooks, class...\n",
       "9998     9999  [science, psychology, nonfiction, children, hi...\n",
       "9999    10000  [fiction, nonfiction, history, biography, ebooks]\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_with_genres = extract_genres(book_tags, tags, genres)\n",
    "books_with_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Non-personalized: popularity-based recommendation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:30.395283Z",
     "iopub.status.busy": "2023-08-31T06:42:30.395019Z",
     "iopub.status.idle": "2023-08-31T06:42:30.447023Z",
     "shell.execute_reply": "2023-08-31T06:42:30.446422Z",
     "shell.execute_reply.started": "2023-08-31T06:42:30.395261Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reduce data (make sampling)\n",
    "book_id_limit = 2500\n",
    "user_id_limit = 13356\n",
    "book_data_small  = book_copy.drop(book_copy[book_copy['book_id'] > book_id_limit].copy().index)\n",
    "rating_data_small = rating_data.loc[(rating_data['user_id'] <= user_id_limit) & (rating_data['book_id'] <= book_id_limit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:30.448161Z",
     "iopub.status.busy": "2023-08-31T06:42:30.447884Z",
     "iopub.status.idle": "2023-08-31T06:42:30.452944Z",
     "shell.execute_reply": "2023-08-31T06:42:30.452156Z",
     "shell.execute_reply.started": "2023-08-31T06:42:30.448142Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1122956, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_data_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:47:49.396491Z",
     "iopub.status.busy": "2023-08-31T12:47:49.396069Z",
     "iopub.status.idle": "2023-08-31T12:47:49.402387Z",
     "shell.execute_reply": "2023-08-31T12:47:49.401590Z",
     "shell.execute_reply.started": "2023-08-31T12:47:49.396465Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def popular_books(rating_data, book_data):\n",
    "    #count the number of ratings given for each book and store the result in a new df called 'rating_count'\n",
    "    rating_count = rating_data.groupby('book_id').count()['rating'].reset_index()\n",
    "    rating_count.rename(columns={'rating':'rating_count'}, inplace=True)\n",
    "    \n",
    "    #count the mean of ratings given for each book and store the result in a new df called 'mean_rating'\n",
    "    mean_rating = rating_data.groupby('book_id').mean().round(2)['rating'].reset_index()\n",
    "    mean_rating.rename(columns={'rating':'mean_rating'}, inplace=True)\n",
    "    \n",
    "    #merge 'rating_count' dataframe with 'mean_rating' dataframe based on 'book_id' column\n",
    "    popular = rating_count.merge(mean_rating, on='book_id')\n",
    "    \n",
    "    #merge df 'popular' with df 'book_copy' based on column 'book_id' then select specific columns and remove duplicate rows based on 'book_id'\n",
    "    popular = popular.merge(book_data, on=\"book_id\").drop_duplicates(\"book_id\")[[\"book_id\",\"rating_count\",\"mean_rating\",\"authors\",\"original_publication_year\",\"original_title\",\"image_url\"]]\n",
    "\n",
    "    #merge df 'popular' with genres\n",
    "    popular_with_genres = popular.merge(books_with_genres, on=\"book_id\").drop_duplicates(\"book_id\")[[\"book_id\",\"rating_count\",\"mean_rating\",\"authors\",\"original_publication_year\",\"original_title\",\"genres\",\"image_url\"]]\n",
    "    \n",
    "    return popular_with_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T13:21:16.558216Z",
     "iopub.status.busy": "2023-08-31T13:21:16.557827Z",
     "iopub.status.idle": "2023-08-31T13:21:16.618599Z",
     "shell.execute_reply": "2023-08-31T13:21:16.617979Z",
     "shell.execute_reply.started": "2023-08-31T13:21:16.558191Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5250</td>\n",
       "      <td>4.29</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>[thriller, science, fiction, fantasy, suspense...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4892</td>\n",
       "      <td>4.15</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>[mystery, science, fiction, fantasy, children,...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4879</td>\n",
       "      <td>4.32</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>[mystery, fiction, crime, history, contemporar...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  rating_count  mean_rating                      authors  \\\n",
       "0        1          5250         4.29              Suzanne Collins   \n",
       "1        2          4892         4.15  J.K. Rowling, Mary GrandPré   \n",
       "3        4          4879         4.32                   Harper Lee   \n",
       "\n",
       "   original_publication_year                            original_title  \\\n",
       "0                       2008                          The Hunger Games   \n",
       "1                       1997  Harry Potter and the Philosopher's Stone   \n",
       "3                       1960                     To Kill a Mockingbird   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [thriller, science, fiction, fantasy, suspense...   \n",
       "1  [mystery, science, fiction, fantasy, children,...   \n",
       "3  [mystery, fiction, crime, history, contemporar...   \n",
       "\n",
       "                                           image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603m...  \n",
       "1  https://images.gr-assets.com/books/1474154022m...  \n",
       "3  https://images.gr-assets.com/books/1361975680m...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_with_genres = popular_books(rating_data_small, book_data_small)\n",
    "#show the order of values from largest to smallest\n",
    "top_30 = popular_with_genres.sort_values(\"rating_count\", ascending=False).head(30)\n",
    "top_30.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T13:21:51.385341Z",
     "iopub.status.busy": "2023-08-31T13:21:51.384949Z",
     "iopub.status.idle": "2023-08-31T13:21:51.393762Z",
     "shell.execute_reply": "2023-08-31T13:21:51.393195Z",
     "shell.execute_reply.started": "2023-08-31T13:21:51.385317Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(top_30, open('output/popular.pkl','wb'))\n",
    "pickle.dump(popular_with_genres, open('output/popular_with_genres.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Personalized recommender system**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 approach we train with cross validation to obtain the best model:\n",
    "a. Baseline Approach\n",
    "b. KNN (Basic and Baseline)\n",
    "c. Matrix Factorization (SVD and NMF)\n",
    "\n",
    "The total number of users is more than the number of items, so for personalized recommender systems, *User-to-User Collaborative Filtering (User CF)* is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:31.398067Z",
     "iopub.status.busy": "2023-08-31T06:42:31.397444Z",
     "iopub.status.idle": "2023-08-31T06:42:31.423867Z",
     "shell.execute_reply": "2023-08-31T06:42:31.423306Z",
     "shell.execute_reply.started": "2023-08-31T06:42:31.398044Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load library\n",
    "import surprise\n",
    "from surprise import accuracy, Dataset, Reader, BaselineOnly, KNNBasic, KNNBaseline, SVD, NMF\n",
    "from surprise.model_selection.search import RandomizedSearchCV\n",
    "from surprise.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation Train-Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:32.998450Z",
     "iopub.status.busy": "2023-08-31T06:42:32.998075Z",
     "iopub.status.idle": "2023-08-31T06:42:33.497386Z",
     "shell.execute_reply": "2023-08-31T06:42:33.496737Z",
     "shell.execute_reply.started": "2023-08-31T06:42:32.998427Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make matrix\n",
    "#copy rating_data and make pivot to check total 'user_id' and 'book_id'\n",
    "user_rating_pivot = rating_data_small.pivot(index='user_id',columns='book_id',values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:33.928829Z",
     "iopub.status.busy": "2023-08-31T06:42:33.928171Z",
     "iopub.status.idle": "2023-08-31T06:42:33.932116Z",
     "shell.execute_reply": "2023-08-31T06:42:33.931355Z",
     "shell.execute_reply.started": "2023-08-31T06:42:33.928805Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize a Reader object in the Surprise library to read rating data on a scale of 1-5\n",
    "reader = Reader(rating_scale = (1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:34.843421Z",
     "iopub.status.busy": "2023-08-31T06:42:34.843051Z",
     "iopub.status.idle": "2023-08-31T06:42:35.782654Z",
     "shell.execute_reply": "2023-08-31T06:42:35.781845Z",
     "shell.execute_reply.started": "2023-08-31T06:42:34.843397Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>315</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5\n",
       "2        2      260       5\n",
       "4        2     2318       3\n",
       "5        2       26       4\n",
       "6        2      315       3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reads the rating data and converts it into a format that can be used to load the recommendation dataset from df 'rating_data'\n",
    "dataset = Dataset.load_from_df(rating_data_small[['user_id', 'book_id', 'rating']].copy(), reader)\n",
    "#show data\n",
    "dataset.df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:35.784130Z",
     "iopub.status.busy": "2023-08-31T06:42:35.783852Z",
     "iopub.status.idle": "2023-08-31T06:42:37.198901Z",
     "shell.execute_reply": "2023-08-31T06:42:37.198275Z",
     "shell.execute_reply.started": "2023-08-31T06:42:35.784110Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split dataset into training data and test data\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:37.200026Z",
     "iopub.status.busy": "2023-08-31T06:42:37.199751Z",
     "iopub.status.idle": "2023-08-31T06:42:37.204788Z",
     "shell.execute_reply": "2023-08-31T06:42:37.204025Z",
     "shell.execute_reply.started": "2023-08-31T06:42:37.200007Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(898364, 224592)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate splitting\n",
    "train_data.n_ratings, len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baselineonly calculates the predicted value based on the baseline (global, user, and item averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:37.206474Z",
     "iopub.status.busy": "2023-08-31T06:42:37.206126Z",
     "iopub.status.idle": "2023-08-31T06:42:37.210720Z",
     "shell.execute_reply": "2023-08-31T06:42:37.210007Z",
     "shell.execute_reply.started": "2023-08-31T06:42:37.206456Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x7f216f860280>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize\n",
    "model_baseline = BaselineOnly()\n",
    "model_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:42:37.211799Z",
     "iopub.status.busy": "2023-08-31T06:42:37.211543Z",
     "iopub.status.idle": "2023-08-31T06:43:20.287586Z",
     "shell.execute_reply": "2023-08-31T06:43:20.286971Z",
     "shell.execute_reply.started": "2023-08-31T06:42:37.211779Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "#perform cross-validation on the initialized recommendation model using the 'BaselineOnly'\n",
    "cv_baseline = cross_validate(algo=model_baseline, data=dataset, cv=5,measures=['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:43:20.289187Z",
     "iopub.status.busy": "2023-08-31T06:43:20.288863Z",
     "iopub.status.idle": "2023-08-31T06:43:20.293838Z",
     "shell.execute_reply": "2023-08-31T06:43:20.293090Z",
     "shell.execute_reply.started": "2023-08-31T06:43:20.289166Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8792313203106795"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv result\n",
    "cv_baseline_rmse = cv_baseline['test_rmse'].mean()\n",
    "cv_baseline_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. KNN Basic and Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T10:49:16.048281Z",
     "iopub.status.busy": "2023-08-31T10:49:16.047896Z",
     "iopub.status.idle": "2023-08-31T10:49:16.052114Z",
     "shell.execute_reply": "2023-08-31T10:49:16.051479Z",
     "shell.execute_reply.started": "2023-08-31T10:49:16.048257Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initialization of parameters that will be used in a randomized search\n",
    "#for hyperparameters in the recommendation model with the KNNBaseline method\n",
    "param_dist = {'k':list(np.arange(start=20, stop=40, step=5)),\n",
    "          'sim_options':{'name':['pearson_baseline'],'user_based':['True']}, 'min_k': [1, 2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#randomized search for hyperparameters in the recommendation model with the KNNBasic method\n",
    "knn_basic = RandomizedSearchCV(algo_class=KNNBasic, param_distributions = param_dist, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T06:43:29.889679Z",
     "iopub.status.busy": "2023-08-31T06:43:29.889312Z",
     "iopub.status.idle": "2023-08-31T10:42:39.507031Z",
     "shell.execute_reply": "2023-08-31T10:42:39.506333Z",
     "shell.execute_reply.started": "2023-08-31T06:43:29.889658Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "knn_basic.fit(data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T10:49:25.069132Z",
     "iopub.status.busy": "2023-08-31T10:49:25.068747Z",
     "iopub.status.idle": "2023-08-31T10:49:25.072526Z",
     "shell.execute_reply": "2023-08-31T10:49:25.071903Z",
     "shell.execute_reply.started": "2023-08-31T10:49:25.069107Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#randomized search for hyperparameters in the recommendation model with the KNNBaseline method\n",
    "knn_search = RandomizedSearchCV(algo_class=KNNBaseline, param_distributions = param_dist, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T06:15:58.964154Z",
     "iopub.status.busy": "2023-08-30T06:15:58.963760Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "#process search hyperparams\n",
    "knn_search.fit(data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(knn_search.best_params[\"rmse\"],open('output/knn_baseline.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Matrix Factorization (SVD and NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T11:43:21.778004Z",
     "iopub.status.busy": "2023-08-31T11:43:21.777633Z",
     "iopub.status.idle": "2023-08-31T11:43:21.781589Z",
     "shell.execute_reply": "2023-08-31T11:43:21.780941Z",
     "shell.execute_reply.started": "2023-08-31T11:43:21.777977Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_SVD = {'lr_all' : [1,0.1,0.01,0.001], 'n_factors' : [50,100],\n",
    "              'reg_all' : [1,0.1,0.01, 0.02]\n",
    "              }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T11:43:24.878189Z",
     "iopub.status.busy": "2023-08-31T11:43:24.877809Z",
     "iopub.status.idle": "2023-08-31T11:55:25.604905Z",
     "shell.execute_reply": "2023-08-31T11:55:25.604227Z",
     "shell.execute_reply.started": "2023-08-31T11:43:24.878165Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svd_search = RandomizedSearchCV(algo_class=SVD, param_distributions = params_SVD, cv=5)\n",
    "svd_search.fit(data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T11:55:25.606833Z",
     "iopub.status.busy": "2023-08-31T11:55:25.606446Z",
     "iopub.status.idle": "2023-08-31T11:55:25.610928Z",
     "shell.execute_reply": "2023-08-31T11:55:25.610263Z",
     "shell.execute_reply.started": "2023-08-31T11:55:25.606800Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_NMF = {'n_factors': np.arange(5, 50, 5),\n",
    "              'n_epochs': np.arange(10, 100, 10)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T11:55:25.612599Z",
     "iopub.status.busy": "2023-08-31T11:55:25.611962Z",
     "iopub.status.idle": "2023-08-31T12:17:20.369400Z",
     "shell.execute_reply": "2023-08-31T12:17:20.368713Z",
     "shell.execute_reply.started": "2023-08-31T11:55:25.612568Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nmf_search = RandomizedSearchCV(algo_class=NMF, param_distributions = params_NMF, cv=5)\n",
    "nmf_search.fit(data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary CV of Multiple Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:17:20.371698Z",
     "iopub.status.busy": "2023-08-31T12:17:20.371283Z",
     "iopub.status.idle": "2023-08-31T12:17:20.383417Z",
     "shell.execute_reply": "2023-08-31T12:17:20.382858Z",
     "shell.execute_reply.started": "2023-08-31T12:17:20.371664Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Performance - RMSE</th>\n",
       "      <th>Model Condiguration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.879231</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Basic</td>\n",
       "      <td>0.894693</td>\n",
       "      <td>{'k': 30, 'sim_options': {'name': 'pearson_bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Baseline</td>\n",
       "      <td>0.840927</td>\n",
       "      <td>{'k': 30, 'sim_options': {'name': 'pearson_bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVD</td>\n",
       "      <td>0.864923</td>\n",
       "      <td>{'lr_all': 0.01, 'n_factors': 50, 'reg_all': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NMF</td>\n",
       "      <td>0.873761</td>\n",
       "      <td>{'n_factors': 35, 'n_epochs': 80}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  CV Performance - RMSE  \\\n",
       "0      Baseline               0.879231   \n",
       "1     KNN Basic               0.894693   \n",
       "2  KNN Baseline               0.840927   \n",
       "3           SVD               0.864923   \n",
       "4           NMF               0.873761   \n",
       "\n",
       "                                 Model Condiguration  \n",
       "0                                                N/A  \n",
       "1  {'k': 30, 'sim_options': {'name': 'pearson_bas...  \n",
       "2  {'k': 30, 'sim_options': {'name': 'pearson_bas...  \n",
       "3  {'lr_all': 0.01, 'n_factors': 50, 'reg_all': 0.1}  \n",
       "4                  {'n_factors': 35, 'n_epochs': 80}  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summarize performance\n",
    "summary_df = pd.DataFrame({'Model': ['Baseline', 'KNN Basic','KNN Baseline', 'SVD', 'NMF'],\n",
    "                           'CV Performance - RMSE': [cv_baseline_rmse,knn_basic.best_score['rmse'],knn_search.best_score['rmse'],svd_search.best_score['rmse'],nmf_search.best_score['rmse']],\n",
    "                           'Model Condiguration':['N/A',f'{knn_basic.best_params[\"rmse\"]}',f'{knn_search.best_params[\"rmse\"]}',f'{svd_search.best_params[\"rmse\"]}',f'{nmf_search.best_params[\"rmse\"]}']})\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Best Model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:23:47.208320Z",
     "iopub.status.busy": "2023-08-31T12:23:47.207938Z",
     "iopub.status.idle": "2023-08-31T12:23:47.212870Z",
     "shell.execute_reply": "2023-08-31T12:23:47.212157Z",
     "shell.execute_reply.started": "2023-08-31T12:23:47.208295Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 30,\n",
       " 'sim_options': {'name': 'pearson_baseline', 'user_based': 'True'},\n",
       " 'min_k': 3}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best hyperparams combination\n",
    "#intialize ber hyperparams\n",
    "best_params = knn_search.best_params['rmse']\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:23:58.088234Z",
     "iopub.status.busy": "2023-08-31T12:23:58.087847Z",
     "iopub.status.idle": "2023-08-31T12:25:43.224428Z",
     "shell.execute_reply": "2023-08-31T12:25:43.223580Z",
     "shell.execute_reply.started": "2023-08-31T12:23:58.088211Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x7f213c1e4370>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create obj. and retrain whole train data\n",
    "model_best = KNNBaseline(**best_params)\n",
    "model_best.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:25:43.225984Z",
     "iopub.status.busy": "2023-08-31T12:25:43.225693Z",
     "iopub.status.idle": "2023-08-31T12:28:37.446289Z",
     "shell.execute_reply": "2023-08-31T12:28:37.445684Z",
     "shell.execute_reply.started": "2023-08-31T12:25:43.225963Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8419\n"
     ]
    }
   ],
   "source": [
    "#predict test data using best model\n",
    "test_pred = model_best.test(test_data)\n",
    "test_rmse = accuracy.rmse(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:30:45.358323Z",
     "iopub.status.busy": "2023-08-31T12:30:45.357934Z",
     "iopub.status.idle": "2023-08-31T12:30:45.366354Z",
     "shell.execute_reply": "2023-08-31T12:30:45.365838Z",
     "shell.execute_reply.started": "2023-08-31T12:30:45.358299Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE-CV-Tuning</th>\n",
       "      <th>RMSE-Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User to User CF</td>\n",
       "      <td>0.840927</td>\n",
       "      <td>0.841932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  RMSE-CV-Tuning  RMSE-Test\n",
       "0  User to User CF        0.840927   0.841932"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summarize RMSE tuning dan test\n",
    "summary_test_df = pd.DataFrame({'Model' : ['User to User CF'],\n",
    "                                'RMSE-CV-Tuning': [knn_search.best_score['rmse']],\n",
    "                                'RMSE-Test': [test_rmse]})\n",
    "\n",
    "summary_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:58:07.958360Z",
     "iopub.status.busy": "2023-08-31T12:58:07.957690Z",
     "iopub.status.idle": "2023-08-31T12:58:07.967794Z",
     "shell.execute_reply": "2023-08-31T12:58:07.967043Z",
     "shell.execute_reply.started": "2023-08-31T12:58:07.958336Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=2, iid=4, r_ui=None, est=4.886242510686152, details={'actual_k': 30, 'was_impossible': False})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict user_id = 2 and book_id = 4\n",
    "sample_prediction = model_best.predict(uid = 2, iid = 4)\n",
    "sample_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:58:38.260461Z",
     "iopub.status.busy": "2023-08-31T12:58:38.260045Z",
     "iopub.status.idle": "2023-08-31T12:58:38.264717Z",
     "shell.execute_reply": "2023-08-31T12:58:38.264051Z",
     "shell.execute_reply.started": "2023-08-31T12:58:38.260435Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your get_unrated_book_ids, predict_and_sort_ratings, and get_top_predicted_books functions here\n",
    "#make function\n",
    "def get_unrated_book_ids(rating_data, user_id):\n",
    "    \"\"\"\n",
    "    Gets a list of book IDs that a user has not rated yet.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rating_data : DataFrame\n",
    "        The DataFrame containing the rating data.\n",
    "    user_id : int\n",
    "        The ID of the user for whom we want to find unrated book IDs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    unrated_book_ids : set\n",
    "        A set of book IDs that the user has not rated.\n",
    "    \"\"\"\n",
    "    #get unique book_id\n",
    "    unique_book_ids = set(rating_data['book_id'])\n",
    "    #get book_id that is rated by user_id = 2\n",
    "    rated_book_ids = set(rating_data.loc[rating_data['user_id'] == user_id, 'book_id'])\n",
    "    #find unrated book_id\n",
    "    unrated_book_ids = unique_book_ids.difference(rated_book_ids)\n",
    "    \n",
    "    return unrated_book_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T13:08:08.151398Z",
     "iopub.status.busy": "2023-08-31T13:08:08.150720Z",
     "iopub.status.idle": "2023-08-31T13:08:08.646486Z",
     "shell.execute_reply": "2023-08-31T13:08:08.645837Z",
     "shell.execute_reply.started": "2023-08-31T13:08:08.151373Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4, 6, 7, 9, 11, 12, 13, 14]\n"
     ]
    }
   ],
   "source": [
    "#check result function and manual\n",
    "unrated_books = get_unrated_book_ids(rating_data, 2)\n",
    "unrated_books_lst = list(unrated_books)\n",
    "print(unrated_books_lst[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T13:08:25.507129Z",
     "iopub.status.busy": "2023-08-31T13:08:25.506739Z",
     "iopub.status.idle": "2023-08-31T13:08:25.512223Z",
     "shell.execute_reply": "2023-08-31T13:08:25.511576Z",
     "shell.execute_reply.started": "2023-08-31T13:08:25.507102Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make function\n",
    "def predict_and_sort_ratings(model, user_id, unrated_book_ids):\n",
    "    \"\"\"\n",
    "    Predicts and sorts unrated books based on predicted ratings for a given user.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : object\n",
    "        The collaborative filtering model used for predictions.\n",
    "    user_id : int\n",
    "        The ID of the user for whom we want to predict and sort unrated books.\n",
    "    unrated_book_ids : list\n",
    "        A list of book IDs that the user has not rated yet.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predicted_unrated_book_df : DataFrame\n",
    "        A DataFrame containing the predicted ratings and book IDs,\n",
    "        sorted in descending order of predicted ratings.\n",
    "    \"\"\"\n",
    "\n",
    "    #initialize\n",
    "    predicted_unrated_book = {\n",
    "        'user_id': user_id,\n",
    "        'book_id': [],\n",
    "        'predicted_rating': []\n",
    "    }\n",
    "    \n",
    "    #loop all unrated book\n",
    "    for book_id in unrated_book_ids:\n",
    "        #make predict\n",
    "        pred_id = model.predict(uid=predicted_unrated_book['user_id'],\n",
    "                                iid=book_id)\n",
    "        #append\n",
    "        predicted_unrated_book['book_id'].append(book_id)\n",
    "        predicted_unrated_book['predicted_rating'].append(pred_id.est)\n",
    "\n",
    "    #create df\n",
    "    predicted_unrated_book_df = pd.DataFrame(predicted_unrated_book).sort_values('predicted_rating',\n",
    "                                                                                  ascending=False)\n",
    "\n",
    "    return predicted_unrated_book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T13:08:54.152275Z",
     "iopub.status.busy": "2023-08-31T13:08:54.151890Z",
     "iopub.status.idle": "2023-08-31T13:08:54.898682Z",
     "shell.execute_reply": "2023-08-31T13:08:54.898036Z",
     "shell.execute_reply.started": "2023-08-31T13:08:54.152251Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2</td>\n",
       "      <td>2244</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>2</td>\n",
       "      <td>780</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>2</td>\n",
       "      <td>2209</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2</td>\n",
       "      <td>422</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>2</td>\n",
       "      <td>2101</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>2</td>\n",
       "      <td>2340</td>\n",
       "      <td>2.702617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>2.640711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>2.516687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>2</td>\n",
       "      <td>1793</td>\n",
       "      <td>1.917401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>2</td>\n",
       "      <td>1409</td>\n",
       "      <td>1.794502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9935 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  book_id  predicted_rating\n",
       "2196        2     2244          5.000000\n",
       "740         2      780          5.000000\n",
       "2161        2     2209          5.000000\n",
       "385         2      422          5.000000\n",
       "2055        2     2101          5.000000\n",
       "...       ...      ...               ...\n",
       "2291        2     2340          2.702617\n",
       "19          2       34          2.640711\n",
       "1081        2     1125          2.516687\n",
       "1747        2     1793          1.917401\n",
       "1365        2     1409          1.794502\n",
       "\n",
       "[9935 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_books_df = predict_and_sort_ratings(model_best,2,unrated_book_ids=unrated_books)\n",
    "predicted_books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T13:09:55.982026Z",
     "iopub.status.busy": "2023-08-31T13:09:55.981623Z",
     "iopub.status.idle": "2023-08-31T13:09:55.987347Z",
     "shell.execute_reply": "2023-08-31T13:09:55.986681Z",
     "shell.execute_reply.started": "2023-08-31T13:09:55.982002Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_top_predicted_books(model, k, user_id, rating_data, book_data):\n",
    "    \"\"\"\n",
    "    Gets the top predicted books for a given user based on a collaborative filtering model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : object\n",
    "        The collaborative filtering model used for predictions\n",
    "    k : int\n",
    "        The number of top predicted books to retrieve\n",
    "    user_id : int\n",
    "        The ID of the user for whom to get top predicted books\n",
    "    rating_data : DataFrame\n",
    "        The DataFrame containing the rating data\n",
    "    book_data : DataFrame\n",
    "        The DataFrame containing the book details\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_books_df : DataFrame\n",
    "        A DataFrame containing the top predicted books along with their details\n",
    "    \"\"\"\n",
    "\n",
    "    # Get unrated book IDs for the user\n",
    "    unrated_book_ids = get_unrated_book_ids(rating_data, user_id)\n",
    "\n",
    "    # Predict and sort unrated books\n",
    "    predicted_books_df = predict_and_sort_ratings(model, user_id, unrated_book_ids)\n",
    "\n",
    "    # Get the top k predicted books\n",
    "    top_predicted_books = predicted_books_df.head(k).copy()\n",
    "\n",
    "    # Add book details to the top predicted books\n",
    "    top_predicted_books['authors'] = book_data.loc[top_predicted_books['book_id'], 'authors'].values\n",
    "    top_predicted_books['original_publication_year'] = book_data.loc[top_predicted_books['book_id'], 'original_publication_year'].values\n",
    "    top_predicted_books['original_title'] = book_data.loc[top_predicted_books['book_id'], 'original_title'].values\n",
    "    top_predicted_books['image_url'] = book_data.loc[top_predicted_books['book_id'], 'image_url'].values\n",
    "\n",
    "    return top_predicted_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T13:10:01.338661Z",
     "iopub.status.busy": "2023-08-31T13:10:01.338274Z",
     "iopub.status.idle": "2023-08-31T13:10:02.150015Z",
     "shell.execute_reply": "2023-08-31T13:10:02.149257Z",
     "shell.execute_reply.started": "2023-08-31T13:10:01.338637Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>2</td>\n",
       "      <td>2209</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ursula K. Le Guin</td>\n",
       "      <td>1974</td>\n",
       "      <td>The Dispossessed</td>\n",
       "      <td>https://images.gr-assets.com/books/1353467455m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>2</td>\n",
       "      <td>780</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Scott Westerfeld</td>\n",
       "      <td>2006</td>\n",
       "      <td>Specials</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>2</td>\n",
       "      <td>1010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Geraldine Brooks</td>\n",
       "      <td>2008</td>\n",
       "      <td>People of the Book</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>2</td>\n",
       "      <td>2256</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Edward Albee</td>\n",
       "      <td>1962</td>\n",
       "      <td>Who's Afraid of Virginia Woolf?</td>\n",
       "      <td>https://images.gr-assets.com/books/1327962277m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2</td>\n",
       "      <td>2244</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lee Child</td>\n",
       "      <td>2004</td>\n",
       "      <td>The Enemy</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>2</td>\n",
       "      <td>2374</td>\n",
       "      <td>5.0</td>\n",
       "      <td>John le Carré</td>\n",
       "      <td>1974</td>\n",
       "      <td>Tinker, Tailor, Soldier, Spy</td>\n",
       "      <td>https://images.gr-assets.com/books/1327889127m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>2</td>\n",
       "      <td>464</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jennifer Weiner</td>\n",
       "      <td>2002</td>\n",
       "      <td>In Her Shoes</td>\n",
       "      <td>https://images.gr-assets.com/books/1435252471m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>2</td>\n",
       "      <td>862</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sam McBratney, Anita Jeram</td>\n",
       "      <td>1988</td>\n",
       "      <td>Guess How Much I Love You</td>\n",
       "      <td>https://images.gr-assets.com/books/1320457007m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2</td>\n",
       "      <td>422</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Kiera Cass</td>\n",
       "      <td>2013</td>\n",
       "      <td>The Elite</td>\n",
       "      <td>https://images.gr-assets.com/books/1391454595m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  book_id  predicted_rating                     authors  \\\n",
       "2161        2     2209               5.0           Ursula K. Le Guin   \n",
       "740         2      780               5.0            Scott Westerfeld   \n",
       "967         2     1010               5.0            Geraldine Brooks   \n",
       "2208        2     2256               5.0                Edward Albee   \n",
       "2196        2     2244               5.0                   Lee Child   \n",
       "2325        2     2374               5.0               John le Carré   \n",
       "427         2      464               5.0             Jennifer Weiner   \n",
       "821         2      862               5.0  Sam McBratney, Anita Jeram   \n",
       "385         2      422               5.0                  Kiera Cass   \n",
       "\n",
       "      original_publication_year                   original_title  \\\n",
       "2161                       1974                 The Dispossessed   \n",
       "740                        2006                         Specials   \n",
       "967                        2008               People of the Book   \n",
       "2208                       1962  Who's Afraid of Virginia Woolf?   \n",
       "2196                       2004                        The Enemy   \n",
       "2325                       1974     Tinker, Tailor, Soldier, Spy   \n",
       "427                        2002                     In Her Shoes   \n",
       "821                        1988        Guess How Much I Love You   \n",
       "385                        2013                        The Elite   \n",
       "\n",
       "                                              image_url  \n",
       "2161  https://images.gr-assets.com/books/1353467455m...  \n",
       "740   https://s.gr-assets.com/assets/nophoto/book/11...  \n",
       "967   https://s.gr-assets.com/assets/nophoto/book/11...  \n",
       "2208  https://images.gr-assets.com/books/1327962277m...  \n",
       "2196  https://s.gr-assets.com/assets/nophoto/book/11...  \n",
       "2325  https://images.gr-assets.com/books/1327889127m...  \n",
       "427   https://images.gr-assets.com/books/1435252471m...  \n",
       "821   https://images.gr-assets.com/books/1320457007m...  \n",
       "385   https://images.gr-assets.com/books/1391454595m...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "predicted_books = get_top_predicted_books(model_best, 9, 2, rating_data_small, book_data_small)\n",
    "predicted_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T13:11:33.340347Z",
     "iopub.status.busy": "2023-08-31T13:11:33.339959Z",
     "iopub.status.idle": "2023-08-31T13:11:33.455857Z",
     "shell.execute_reply": "2023-08-31T13:11:33.455200Z",
     "shell.execute_reply.started": "2023-08-31T13:11:33.340322Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(best_params,open('output/best_params.pkl','wb'))\n",
    "pickle.dump(book_data_small,open('output/books.pkl','wb'))\n",
    "pickle.dump(rating_data_small,open('output/rating.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
